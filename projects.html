<!DOCTYPE html>
<html lang="en">
<head>
	<title>Sarvan Gill</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css?family=Orbitron|Titillium+Web&display=swap" rel="stylesheet"> 
</head>
<body>
	<header>
		<ul class="header-nav">
			<li><a href="index.html">Home</a></li>
			<li><a href="aboutme.html">About Me</a></li>
			<li class="name"><a href="index.html">Sarvan Gill</a></li>
			<li><a href="projects.html">Projects</a></li>
			<li><a href="Sarvan-Resume.pdf">Resume</a></li>
		</ul>

    </header>

    <div class="title">
        <h1>2D Platformer Video Game</h1>
   </div>

   <section class ="intro">
       <div class="teamPart">
            <p>After I quit my job </p>
           <figure>
               <img src="docs/game1.png" alt="game" width="650px" height="350px">
               <figcaption>Progress on the first scene of the game </figcaption>
           </figure>

           <p>
           </p>
       </div>

   </section>

	<div class="title">
        <h1>Photon Mediated Spin Qubit Research</h1>
   </div>

   <section class ="intro">
       <div class="teamPart">
            <p> In 2021-2022, 3 classmates and I reached out to some professors at our University to find a physics research project that interested on.
                We landed on a photonics project with the Quantum Matter Institute. Our sponsor Dr. Jeff Young, wanted us to investigate the theoretical possibility
                of using silicon photonoic cavities to create a qubit. Thus our job was to do research and model what the cavity would look like, the photon-cavity
                interactions as well as simulate these interactions. </p>
           <figure>
               <img src="docs/qubits.PNG" alt="qubits" width="650px" height="350px">
               <figcaption>Diagram explaining cavity interactions</figcaption>
           </figure>

           <p>This project was majorly a theoretical investigation with little coding involved other than the simulations of our theoretical models. 
            A full report of our models and results can be found <a href="docs/quantum.pdf"> here</a>. The introduction of this paper serves appeals to 
            anyone with some physics background. However, the rest of the paper is geared to our sponsors and thus is heavily focused on the physics 
            relevant to the project.
           </p>
       </div>

   </section>

	<div class="title">
        <h1> Kaon Classifier</h1>
   </div>

   <section class ="intro">

       <div class="teamPart">
            <p>In 2020-2021 me and 3 of my classmates took on our first capstone which was to create a machine learning model to help classify an extremely rare kaon decay. This project was done in partnership with TRIUMF
                and our main contact was at the experiment itself at CERN. Our sponsors were physics researchers so they did not have much background knowledge in machine learning. Thus this was my first self directed machine learning
                project. Without going too much into the physics, we were only given numerical data. So wanted to first reconstruct and visualize what the detections looked like and see if we could use these visualizations in a CNN. 
                However, there was more data than just those visualizations, so we used a BDT to train off the other data and then combined the two models.
            </p>
           <figure>
               <img src="docs/kaoncad.PNG" alt="CAD" width="650px" height="350px">
               <figcaption>CAD model I created of the experiment setup at CERN</figcaption>
           </figure>

           <p> Here we can see the Kaon in green and its decay point indicated by the green dot, then we can see the detected particles afterward indicated by the red line. Right after the decay point we see the STRAW detectors which is what 
            we were trying to visualize given the numerical data. The other detectors present in the experiment were used in the BDT. 
           </p>
           <figure>
                <img src="docs/kaoncs.PNG" alt="Cross Sections" width="600px" height="400px">
                <figcaption>Visualization of the STRAW detectors used for the CNN</figcaption>
            </figure>

            <p> In the diagram above you can see a side by side of what the STRAW detectors looked like and what our visualization of the specific straws hit looked like in our CNN. This is what we used to train and we were able to 
                make a decent model with these visualizations. The main goal of this project was not to get an extremely accurate model but to try to isolate which variables have a larger impact on the predicition. With the BDT we were
                able to do exactly that. The physicsits then took our results and are now researching what this means for the decay!
            </p>

           <p> A full report on the CNN and BDTs used and their results can be found <a href="docs/KaonClassifier.pdf"> here</a>. This also includes background information on what data was available and 
            a description and explanation of each of the detector parts along with the justifications for the descisons we made. This report was geared towards both our sponsors at TRIUMF/CERN and our 
            instructors so it should be understandble for anyone with some tech/physics background.
           </p>
       </div>

   </section>

	<div class="title">
        <h1> greenEats</h1>
   </div>

   <section class ="intro">

       <div class="teamPart">
            <p>In 2020 I entered my first hackathon, NwHacks, with 3 of my closest friends. In just 24 hours we were able to come together and create greenEats, an all in one grocery management app.
                The app allowed users to input grocery items into the in app inventory using one of three methods - manual input, taking a picture of the reciept, and speech to text. greenEats then also 
                takes in the expiry date and allows users to sort by expiry. Finally the app allows users to select items in their inventory and would reccommend reciepes based on those items. Due to the large
                number of features we were able to include, greenEats took home the grand prize of first place!

            </p>
           <figure>
               <img src="docs/greenEats.jpg" alt="App" width="400px" height="650px">
               <figcaption>The landing page of the app</figcaption>
           </figure>

           <p> Our devpost shows some more insights into the motivations and technologies used and can be found <a href="https://devpost.com/software/greeneats/"> here</a>
           </p>
       </div>

   </section>

    <div class="title">
         <h1>Parking Bot</h1>
    </div>

    <section class ="intro">

        <div class="teamPart">
            <p>In November 2019, my friend Anthony Ho and I enrolled in a project course that revolved around implementing modern techniques
                (computer vision and machine learning) in a simulated competition.
            </p>
            <p>The competition takes place in a simulated parking lot environment. This parking lot has 2 loops, and inner and an outer loop, 
                2 crosswalks with pedestrians crossing at any given time, and a truck driving around the inner loop. 
            </p>    
            <p>The objective of the 
                competition is to control a robot that goes around this simulated parking lot, and checks if the parked cars have permission 
                to park by reporting all the license plates and spot numbers of the cars. The robot is to do this without hitting the pedestrians
                or the truck and staying within the lanes, failure to do any of these resulted in point deduction.
            </p>
            <figure>
                <img src="Robot/353map.png" alt="Map" width="500px" height="500px">
                <figcaption>An image of the virtual parking lot</figcaption>
            </figure>

            <p> A report of our strategy and implementation can be found <a href="docs/ParkingBot.pdf">here</a>.
            </p>
        </div>

    </section>


    <div class="title">
        <h1>Hedwig the Autonomous Robot</h1>
    </div>

    <section class="intro">
        <div class="teamPart">
            <figure>
                <img src="Robot/TeamPic.jpg" alt="TeamPic" width="650px" height="500px">
                <figcaption>Team 9 (Left to Right): Kausik Krishnakumar, Sarvan Gill, Alex Carbo, Maxwell Yang</figcaption>
            </figure>
            <p>Hedwig is an autonomous robot that was made to compete in the annual 2nd year Engineering Physics robot competition at UBC.
                    The goal of the competition was to create a completely autonomous robot, that was able to navigate a course to
                    precisely pick up stones off of pillars of different heights and place them into a tray.
            </p>
        </div>

    </section>
    
    <section class="competition">
        <div>
                <h2>The Competiton</h2>

                <h4>Hedwig went undefeated in competition!</h4>

                <p>Hedwig performed exceptionally in the competition. Although, we won every battle, Hedwig was not promoted to the finals
                    by the judges desicion. However, after the finals, we were given a chance to fight for second, and Hedwig did not let down!
                </p>
                <p>
                    Below is a video of the second round of the round robin. Although being the second round, this was the first point
                    scored in the competition.
                </p>
                <figure>
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/idC6wWlBNa8" frameborder="0" 
                        allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </figure>
                
                <p>
                    Below is a video of a complete run taken just before competition.
                </p>
                <figure>
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/_ULe31zwrJE" 
                        frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>        
                </figure>
                <p>
                    A fun video from Hedwig's point of view:
                </p>
                <figure>
                        <iframe width="560" height="315" src="https://www.youtube.com/embed/vKIGVJqr8zc" frameborder="0" 
                        allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                </figure>
        </div>
    </section>

    <!-- <section class="info">
        <div>
            <h2>The Robot</h2>
            <div class="general">
                <h3>General</h3>
                <figure>
                    <img src="Robot/RoboPic.png" alt="RobotPic" width="450px" height="550px">
                </figure>
            </div>

        </div>
        
    </section> -->

</body>
</html>
